"""Machine Learning Notes â€“ Explanation
ğŸ“Œ Page 1 â€” Supervised Learning

Machine Learning is a field where machines learn from data.

Supervised learning â†’ Data is labeled (you know the correct answer/output)

Solves:

Regression problems â†’ Predict continuous values (like salary, price, weight)

Classification problems â†’ Predict categories (like pass/fail, spam/not spam)

Types of features:

Input feature (independent variable)

Output feature (dependent variable / target value)

ğŸ“Œ Page 2 â€” Regression Example

Example: CGPA â†’ Package prediction

If CGPA increases, salary (package) also changes â†’ numerical prediction â†’ Regression

Algorithms for regression:

Linear Regression

Ridge Regression

Lasso Regression

Support Vector Regression

Decision Tree Regression

Random Forest Regression

ğŸ“Œ Page 3 â€” Classification Problems

Output is discrete

Examples:

Result prediction â†’ Pass (1) or Fail (0)

Spam detection

Disease prediction

Image classification

ğŸ“Œ Page 4 â€” Unsupervised Learning

Works with unlabeled data

We donâ€™t know the output beforehand

Solves:

Clustering â†’ grouping customers

Dimensionality reduction

Anomaly detection (fraud detection)

Association (shopping patterns)

ğŸ“Œ Page 5 â€” Unsupervised Algorithms

K-Means

DBSCAN

PCA (Principal Component Analysis)

ğŸ“Œ Page 6â€“8 â€” Linear Regression

It is a supervised ML algorithm used for regression

Types:

Simple linear regression â†’ one input

ğ‘Œ
=
ğ‘š
ğ‘‹
+
ğ‘
Y=mX+b

Multiple linear regression â†’ multiple inputs

ğ‘Œ
=
ğ‘š
1
ğ‘‹
1
+
ğ‘š
2
ğ‘‹
2
+
ğ‘
Y=m
1
	â€‹

X
1
	â€‹

+m
2
	â€‹

X
2
	â€‹

+b

Polynomial regression

ğ‘Œ
=
ğ‘
0
+
ğ‘
1
ğ‘‹
+
ğ‘
2
ğ‘‹
2
Y=b
0
	â€‹

+b
1
	â€‹

X+b
2
	â€‹

X
2

Shows graph and formula for best fit line

How to calculate:

Slope (m)

Intercept (b)

ğŸ“Œ Page 9â€“10 â€” Deep Learning & ANN

Deep Learning is a part of AI + ML

ANN â†’ Artificial Neural Network

Structure inspired by the human brain

Example: Placement prediction

Network has:

Input Layer

Hidden Layer

Output Layer

Weights 
ğ‘Š
1
,
ğ‘Š
2
,
.
.
.
W1,W2,... and Bias 
ğ‘
1
,
ğ‘
2
,
.
.
.
b1,b2,... are learnable parameters

ğŸ“Œ Page 11â€“14 â€” Perceptron & Activation Functions

Perceptron â†’ basic unit (neuron)

Activation function decides neuron output

Types shown:

Sigmoid (for binary classification)

Tanh (values: âˆ’1 to 1)

ReLU

Leaky ReLU (fixes dead neuron problem)

Graphs are shown for each function.

ğŸ“Œ Page 15â€“16 â€” Forward Propagation

Inputs are multiplied by weights

Bias is added

Activation function applied layer-by-layer

Final output is the prediction 
ğ‘¦
^
y
^
	â€‹


ğŸ“Œ Page 17â€“18 â€” Loss Functions

Used to check error between actual & predicted value

For Regression:

MSE â†’ Mean Squared Error

MAE â†’ Mean Absolute Error

For Classification:

Binary Cross Entropy (2 classes)

Categorical Cross Entropy (more than 2 classes)

ğŸ“Œ Page 19 â€” Backpropagation

Used for training neural networks

Adjust weights to reduce error

Uses Gradient Descent:

Update formula:

ğ‘Š
ğ‘›
ğ‘’
ğ‘¤
=
ğ‘Š
ğ‘œ
ğ‘™
ğ‘‘
âˆ’
ğœ‚
âˆ‚
ğ¿
âˆ‚
ğ‘Š
W
new
	â€‹

=W
old
	â€‹

âˆ’Î·
âˆ‚W
âˆ‚L
	â€‹


Î· = learning rate

ğŸ“Œ Page 20 â€” Overview

ANN used for tabular data

Shows Input â†’ ANN â†’ Output block diagram

ğŸ¯ Quick Summary
Concept	Type	What it predicts?
Supervised Learning	Labeled data	Regression & Classification
Unsupervised Learning	Unlabeled data	Clustering, grouping
Linear Regression	Regression	Continuous output
ANN / Deep Learning	Supervised	Complex tasks
Loss Functions	Regression & Classification	Measures model error


"""
